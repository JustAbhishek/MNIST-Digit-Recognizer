{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, RepeatVector, TimeDistributed\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Flatten, Input, Reshape, Flatten, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Flatten\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Dataset/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1  = pd.read_csv(\"Dataset/test.csv\")\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df.drop(['label'], axis=1).values\n",
    "train_y = df['label'].values\n",
    "x_test = df1.values\n",
    "\n",
    "print(\"X_train shape\", x_train.shape)\n",
    "print(\"y_test shape\", train_y.shape)\n",
    "print(\"X_test shape\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def resize(img_array):\n",
    "    tmp = np.empty((img_array.shape[0], IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    for i in range(len(img_array)):\n",
    "        img = img_array[i].reshape(28, 28).astype('uint8')\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        img = img.astype('float32')/255\n",
    "        tmp[i] = img\n",
    "        \n",
    "    return tmp\n",
    "\n",
    "x_train = resize(x_train)\n",
    "x_test = resize(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = np.stack((x_train,)*3, axis=-1)\n",
    "X_test_final = np.stack((x_test,)*3, axis=-1)\n",
    "print(X_train_final.shape)\n",
    "print(X_test_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#, num_classes=10\n",
    "y_train_final = to_categorical(train_y, num_classes=10)\n",
    "print(y_train_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train_final, y_train_final, test_size=0.2, random_state=2021)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot first few images\n",
    "import matplotlib.pyplot as plt\n",
    "for i in range(9):\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))\n",
    "# show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n",
    "    val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n",
    "    acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n",
    "    val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n",
    "    \n",
    "    if len(loss_list) == 0:\n",
    "        print('Loss is missing in history')\n",
    "        return \n",
    "    \n",
    "    ## As loss always exists\n",
    "    epochs = range(1,len(history.history[loss_list[0]]) + 1)\n",
    "    \n",
    "    ## Loss\n",
    "    plt.figure(1)\n",
    "    plt.figsize=(10, 10)\n",
    "    for l in loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    for l in val_loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    \n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    ## Accuracy\n",
    "    plt.figure(2)\n",
    "    plt.figsize=(10, 10)\n",
    "    for l in acc_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "    for l in val_acc_list:    \n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparitive-Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(IMG_SIZE, (3, 3), activation='relu', padding='valid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy', verbose=1, patience=5)\n",
    "mc = ModelCheckpoint(filepath='CNN.h5', verbose=1, monitor='val_acc')\n",
    "cb = [es, mc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history1 = model1.fit(X_train, y_train, \n",
    "                    epochs=50, \n",
    "                    batch_size=128, \n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score1 = model1.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test accuracy CNN%:', (score1[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1=model1.predict(X_test, batch_size=128)\n",
    "y_pred_1= pred_1.argmax(axis=-1)\n",
    "\n",
    "y_true_onehot = y_test\n",
    "y_true_label = np.argmax(y_true_onehot, axis=1)\n",
    "y_true = y_true_label\n",
    "y_pred1 = y_pred_1\n",
    "print(y_pred1[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred1)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "plt.imshow(cm, interpolation='nearest', cmap='Pastel1')\n",
    "plt.title('Confusion matrix', size = 15)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(10)\n",
    "plt.xticks(tick_marks, [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], rotation=45, size = 10)\n",
    "plt.yticks(tick_marks, [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], size = 10)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('Actual label', size = 15)\n",
    "plt.xlabel('Predicted label', size = 15)\n",
    "width, height = cm.shape\n",
    "\n",
    "for x in range(width):\n",
    "    for y in range(height):\n",
    "        plt.annotate(str(cm[x][y]), xy=(y, x), \n",
    "                    horizontalalignment='center',\n",
    "                    verticalalignment='center')\n",
    "plt.savefig('CNN.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Neural Network with AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_signal = Input(shape=(32, 32, 3))\n",
    "\n",
    "#ENCODER\n",
    " \n",
    "e = Conv2D(filters = 512, kernel_size = (3, 3), activation='relu', padding='same',  kernel_initializer='he_uniform')(input_signal)\n",
    "e = MaxPooling2D(pool_size = (2, 2), padding='same')(e)\n",
    "e = Dropout(0.1)(e)\n",
    "\n",
    "\n",
    "e = Conv2D(filters = 256, kernel_size = (3, 3), activation='relu', padding='same',  kernel_initializer='he_uniform')(e)\n",
    "e = MaxPooling2D(pool_size = (2, 2), padding='same')(e)\n",
    "e = Dropout(0.1)(e)\n",
    "\n",
    "e = Conv2D(filters = 256, kernel_size = (3, 3), activation='relu', padding='same',  kernel_initializer='he_uniform')(e)\n",
    "e = MaxPooling2D(pool_size = (2, 2), padding='same')(e)\n",
    "e = Dropout(0.1)(e)\n",
    "\n",
    "##DECODER\n",
    "d = Conv2D(256, (3, 3), activation='relu', padding='same',  kernel_initializer='he_uniform')(e)\n",
    "d = MaxPooling2D(pool_size = (2, 2), padding='same')(d)\n",
    "d = Dropout(0.1)(d)\n",
    "\n",
    "d = Conv2D(256, (3, 3), activation='relu', padding='same',  kernel_initializer='he_uniform')(d)\n",
    "d = MaxPooling2D(pool_size = (2, 2), padding='same')(d)\n",
    "d = Dropout(0.1)(d)\n",
    "\n",
    "d = Conv2D(512, (3, 3), activation='relu', padding='same',  kernel_initializer='he_uniform')(d)\n",
    "d = MaxPooling2D(pool_size = (2, 2), padding='same')(d)\n",
    "d = Dropout(0.1)(d)\n",
    "\n",
    "d = Flatten()(d)\n",
    "decoded = Dense(10, activation=\"softmax\")(d)\n",
    "\n",
    "\n",
    "model2 = Model(inputs=input_signal, outputs=decoded)\n",
    "model2.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy', verbose=1, patience=5)\n",
    "mc = ModelCheckpoint(filepath='CNN-AutoEncoder.h5', verbose=1, monitor='val_acc')\n",
    "cb = [es, mc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model2.fit(X_train, y_train, \n",
    "                    epochs=50, \n",
    "                    batch_size=128, \n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=cb)\n",
    "scores = model2.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score2 = model2.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test accuracy CNN%:', (score2[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2=model2.predict(X_test, batch_size=128)\n",
    "y_pred_2= pred_2.argmax(axis=-1)\n",
    "\n",
    "y_true_onehot = y_test\n",
    "y_true_label = np.argmax(y_true_onehot, axis=1)\n",
    "y_true = y_true_label\n",
    "y_pred2 = y_pred_2\n",
    "print(y_pred2[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred2)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "plt.imshow(cm, interpolation='nearest', cmap='Pastel2')\n",
    "plt.title('Confusion matrix', size = 15)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(10)\n",
    "plt.xticks(tick_marks, [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], rotation=45, size = 10)\n",
    "plt.yticks(tick_marks, [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], size = 10)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('Actual label', size = 15)\n",
    "plt.xlabel('Predicted label', size = 15)\n",
    "width, height = cm.shape\n",
    "\n",
    "for x in range(width):\n",
    "    for y in range(height):\n",
    "        plt.annotate(str(cm[x][y]), xy=(y, x), \n",
    "                    horizontalalignment='center',\n",
    "                    verticalalignment='center')\n",
    "plt.savefig('CNN-AutoEncoder.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG-16 with Transfer-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG = VGG16(input_shape=(32, 32, 3), include_top=False, weights='imagenet')\n",
    "VGG.trainable = False\n",
    "\n",
    "model3 = Sequential([\n",
    "    VGG,\n",
    "    Flatten(),\n",
    "    Dense(units=512, activation=\"relu\"),\n",
    "    Dropout(0.1),\n",
    "    Dense(units=256, activation=\"relu\"),\n",
    "    Dropout(0.1),\n",
    "    Dense(units=10, activation=\"softmax\")\n",
    "    \n",
    "])\n",
    "\n",
    "model3.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy', verbose=1, patience=5)\n",
    "mc = ModelCheckpoint(filepath='CNN-VGG16.h5', verbose=1, monitor='val_acc')\n",
    "cb = [es, mc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history3 = model3.fit(X_train, y_train, \n",
    "                    epochs=50, \n",
    "                    batch_size=128, \n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score3 = model3.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test accuracy CNN VGG-16%:', (score3[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_3=model3.predict(X_test, batch_size=128)\n",
    "y_pred_3= pred_3.argmax(axis=-1)\n",
    "\n",
    "y_true_onehot = y_test\n",
    "y_true_label = np.argmax(y_true_onehot, axis=1)\n",
    "y_true = y_true_label\n",
    "y_pred3 = y_pred_3\n",
    "print(y_pred3[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred3)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "plt.imshow(cm, interpolation='nearest', cmap='Paired')\n",
    "plt.title('Confusion matrix', size = 15)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(10)\n",
    "plt.xticks(tick_marks, [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], rotation=45, size = 10)\n",
    "plt.yticks(tick_marks, [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], size = 10)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('Actual label', size = 15)\n",
    "plt.xlabel('Predicted label', size = 15)\n",
    "width, height = cm.shape\n",
    "\n",
    "for x in range(width):\n",
    "    for y in range(height):\n",
    "        plt.annotate(str(cm[x][y]), xy=(y, x), \n",
    "                    horizontalalignment='center',\n",
    "                    verticalalignment='center')\n",
    "plt.savefig('CNN-VGG-16.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG-19 Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG = VGG19(input_shape=(32, 32, 3), include_top=False, weights='imagenet')\n",
    "VGG.trainable = False\n",
    "\n",
    "model4 = Sequential([\n",
    "    VGG,\n",
    "    Flatten(),\n",
    "    Dense(units=512, activation=\"relu\"),\n",
    "    Dropout(0.1),\n",
    "    Dense(units=256, activation=\"relu\"),\n",
    "    Dropout(0.1),\n",
    "    Dense(units=10, activation=\"softmax\")\n",
    "    \n",
    "])\n",
    "\n",
    "model4.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "from ann_visualizer.visualize import ann_viz\n",
    "ann_viz(model4, title=\"MNIST CNN-VGG19 network\", filename=\"CNN-VGG19.gv\")\n",
    "# model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy', verbose=1, patience=5)\n",
    "mc = ModelCheckpoint(filepath='CNN-VGG19.h5', verbose=1, monitor='val_acc')\n",
    "cb = [es, mc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history4 = model4.fit(X_train, y_train, \n",
    "                    epochs=50, \n",
    "                    batch_size=128, \n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=cb)\n",
    "scores = model4.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test accuracy CNN-VGG19-Model%:', (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score4 = model4.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test accuracy CNN VGG-19%:', (score4[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_4=model4.predict(X_test, batch_size=128)\n",
    "y_pred_4= pred_4.argmax(axis=-1)\n",
    "\n",
    "y_true_onehot = y_test\n",
    "y_true_label = np.argmax(y_true_onehot, axis=1)\n",
    "y_true = y_true_label\n",
    "y_pred4 = y_pred_4\n",
    "print(y_pred4[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred4)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "plt.imshow(cm, interpolation='nearest', cmap='Accent')\n",
    "plt.title('Confusion matrix', size = 15)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(10)\n",
    "plt.xticks(tick_marks, [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], rotation=45, size = 10)\n",
    "plt.yticks(tick_marks, [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], size = 10)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('Actual label', size = 15)\n",
    "plt.xlabel('Predicted label', size = 15)\n",
    "width, height = cm.shape\n",
    "\n",
    "for x in range(width):\n",
    "    for y in range(height):\n",
    "        plt.annotate(str(cm[x][y]), xy=(y, x), \n",
    "                    horizontalalignment='center',\n",
    "                    verticalalignment='center')\n",
    "plt.savefig('CNN-VGG-19.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUBMISSION\n",
    "\n",
    "As it is observed that CNN Autoencoder is giving the Highest Test Accuracy of 99.01%\n",
    "\n",
    "We will be submtting that model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing.image import load_img\n",
    "# from tensorflow.keras.preprocessing.image import img_to_array\n",
    "# from tensorflow.keras.models import load_model\n",
    "\n",
    "# IMG_SIZE = 32\n",
    "# # load and prepare the image\n",
    "# def load_image(filename):\n",
    "# # load the image\n",
    "#     img = load_img(filename, grayscale=True, target_size=32)\n",
    "#     img = img_to_array(img)\n",
    "    \n",
    "#     tmp = np.empty((img.shape[0], IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "#     for i in range(len(img)):\n",
    "#         img = img[i].reshape(28, 28).astype('uint8')\n",
    "#         img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "#         img = img.astype('float32')/255\n",
    "#         tmp[i] = img\n",
    "        \n",
    "#     return tmp\n",
    " \n",
    "# # load an image and predict the class\n",
    "# def run_example():\n",
    "# # load the image\n",
    "#     img = load_image('sample_image.png')\n",
    "#     # load model\n",
    "#     model = load_model('CNN-AutoEncoder.h5')\n",
    "#     # predict the class\n",
    "#     digit = model.predict(img)\n",
    "#     print(digit[0])\n",
    "\n",
    "# run_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "img = Image.open('sample_image.png')\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img_array = np.asarray(img)\n",
    "print(img_array.shape)\n",
    "# resized = resize(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
